import pandas as pd
import sqlite3
import re
from rapidfuzz import fuzz, process
import numpy as np

# CONSTANTS
user_q = "ground beef"
food_list = [
    "rice vinegar",
    "apple cider vinegar",
    "soy sauce",
    "chicken breast",
    "garlic",
    "onion",
    "olive oil",
    "apple",
    "cider",
    "vinegar",
]
food_set = set(food_list)



def preprocess(user_q):
    user_q = user_q.lower()
    user_q = re.sub(r"[^a-z0-9\s]", "", user_q)
    tokens = user_q.split()
    return tokens

def fuzzy_match_foods(token, food_set, min_score=80):
    matches = []
    for food in food_set:
        score = fuzz.ratio(token, food)
        if score >= min_score:
            matches.append((food, score))
    return matches

def fuzzy_token_spellcheck(tokens, food_list):  
    for i, tok in enumerate(tokens):
        if len(tok) <= 3:
            continue
        matches = fuzzy_match_foods(tok, food_list)
        if matches:
            # Keep the best match only
            best_food, _ = max(matches, key=lambda x: x[1])
            tokens[i] = best_food
    return tokens

def generate_ngrams(tokens, max_n=3):
    ngrams = []
    n = len(tokens)
    for size in range(max_n, 0, -1):  # start big!
        for i in range(n - size + 1):
            ngram = " ".join(tokens[i:i+size])
            ngrams.append(ngram)
    return ngrams

# This function was generated by Claude [Prompt found in Refrence 1]
def hash_match(query, food_set, max_ngram=4):
    tokens = preprocess(query)
    tokens = fuzzy_token_spellcheck(tokens, food_set)
    found = []
    used_indices = set()  # Track which token positions have been used
    
    # Iterate from largest to smallest n-gram size
    for size in range(max_ngram, 0, -1):
        i = 0
        while i <= len(tokens) - size:
            # Skip if any token in this range has already been used
            if any(idx in used_indices for idx in range(i, i + size)):
                i += 1
                continue
            
            # Generate the n-gram
            ngram = " ".join(tokens[i:i+size])
            # Check if it matches a food
            if ngram in food_set:
                found.append(ngram)
                # Mark these indices as used
                for idx in range(i, i + size):
                    used_indices.add(idx)
                # Move past this match
                i += size
            elif ngram + " raw" in food_set:
                found.append(ngram + " raw")
                # Mark these indices as used
                for idx in range(i, i + size):
                    used_indices.add(idx)
                # Move past this match
                i += size
            else:
                i += 1
    
    return found, used_indices

_model = None

def set_model(model):
    global _model
    _model = model

def build_food_embeddings(food_list):
    food_embeddings = _model.encode(food_list, convert_to_numpy=True, normalize_embeddings=True)
    return food_embeddings

def embedding_fallback(query, food_list, food_embeddings, top_k=1, c=.0):
    query_emb = _model.encode([query], convert_to_numpy=True, normalize_embeddings=True)[0]
    sims = np.dot(food_embeddings, query_emb)
    
    top_idx = np.argsort(sims)[::-1][:top_k] 
    candidates = [(food_list[i], float(sims[i])) for i in top_idx]
    
    filtered = [cand for cand in candidates if cand[1] >= c]
    embedding_matches = filtered #[cand for cand in filtered if cand not in hash_matches]
    
    return embedding_matches
#embedding_fallback("unprocessed",real_food_list, real_food_embeddings)


def embedding_fallback_tokens(query, food_list, food_embeddings, top_k=1, c=.70):
    tokens = preprocess(query)
    embedding_matches = []
    for tok in tokens:
        tok_emb = _model.encode([tok], convert_to_numpy=True, normalize_embeddings=True)[0]
        sims = np.dot(food_embeddings, tok_emb)
    
        top_idx = np.argsort(sims)[::-1][:top_k] 
        candidates = [(food_list[i], float(sims[i])) for i in top_idx]

        filtered = [cand for cand in candidates if cand[1] >= c]   
        filtered_strings = [item[0] for item in filtered]
        embedding_matches = embedding_matches + filtered_strings

    embedding_matches = list(dict.fromkeys(embedding_matches))
    return embedding_matches

#embedding_fallback_tokens("I have cream cheese, wine, chicken breast, pork, and mushrooms in my fridge",real_food_list, real_food_embeddings)


def embedding_fallback_ngrams(query, food_list, food_embeddings, top_k=1, c=.70):
    tokens = preprocess(query)
    ngrams = generate_ngrams(tokens)
    embedding_matches = []
    for ngram in ngrams:
        ngram_emb = _model.encode([ngram], convert_to_numpy=True, normalize_embeddings=True)[0]
        sims = np.dot(food_embeddings, ngram_emb)
    
        top_idx = np.argsort(sims)[::-1][:top_k] 
        candidates = [(food_list[i], float(sims[i])) for i in top_idx]
    
        filtered = [cand for cand in candidates if cand[1] >= c]   
        filtered_strings = [item[0] for item in filtered]
        embedding_matches = embedding_matches + filtered_strings

    embedding_matches = list(dict.fromkeys(embedding_matches))
    return embedding_matches

#embedding_fallback_ngrams("I have cream cheese, wine, chicken breast, and mushrooms in my fridge",real_food_list, real_food_embeddings)


def embedding_sim_test(query, food_list, food_embeddings, top_k=1):
    print(query)
    query_emb = _model.encode([query], convert_to_numpy=True, normalize_embeddings=True)[0]
    sims = np.dot(food_embeddings, query_emb)
    
    top_idx = np.argsort(sims)[::-1][:top_k] 
    candidates = [(food_list[i], float(sims[i])) for i in top_idx]
    return candidates

#embedding_sim_test("I have cream cheese, wine, chicken breast, pork, and mushrooms in my fridge",real_food_list, real_food_embeddings)


def get_foods():
    conn = sqlite3.connect('Nutrition.db')
    query = """
    SELECT food
    FROM nutrition_facts;
    """
    food_df = pd.read_sql_query(query, conn)
    conn.close()
    return food_df['food'].tolist()

def match_query_to_column(query, max_ngram=4):
    food_list = get_foods()

    food_set = set(food_list)
    food_embeddings = build_food_embeddings(food_list)

    hash_matches, _ = hash_match(query, food_set, max_ngram=max_ngram)
    
    embedding_matches = embedding_fallback_tokens(query, food_list, food_embeddings, top_k=1)
    
    return hash_matches, embedding_matches

#match_query_to_column(user_q, food_list, food_set, food_embeddings)

def get_food_nutrition(foods):
    placeholders = ','.join('?' * len(foods))
    conn = sqlite3.connect('Nutrition.db')
    query = f"""
    SELECT food, "Caloric Value", Fat, "Saturated Fats","Monounsaturated Fats", "Carbohydrates", "Sugars", "Protein", "Dietary Fiber", "Cholesterol", "Sodium",
    "Vitamin A", "Vitamin B1""Vitamin C", "Vitamin D", "Vitamin E", "Calcium","Iron","Potassium", "Nutrition Density"
    FROM nutrition_facts
    WHERE food IN ({placeholders});
    """
    food_df = pd.read_sql_query(query, conn, params=foods)
    conn.close()
    return food_df

def format_nutdf(food_nutrients_df):
    print(food_nutrients_df)

def format_nutrition_data(food_nutrients_df, limit=20):
    df_subset = food_nutrients_df.head(limit)
    
    lines = []
    for _, row in df_subset.iterrows():
        nutrients = ", ".join(
            f"{col}: {row[col]:.1f}" if isinstance(row[col], (int, float))
            else f"{col}: {row[col]}"
            for col in food_nutrients_df.columns if col != 'food'
        )
        lines.append(f"- {row['food']}: {nutrients}")
    
    return "\n".join(lines)

def get_foodnutrition_in_userquery(query):
    hash_matches, embedding_matches = match_query_to_column(query)
    found_foods = hash_matches + embedding_matches
    food_nutrients_df = get_food_nutrition(found_foods)
    
    return format_nutrition_data(food_nutrients_df)

#print(get_foodnutrition_in_userquery("I have cream cheese, wine, chicken breast, pork, and mushrooms in my fridge"))

#########################################
#########################################
###############HIGHLOW###################
#########################################
#########################################


NUTRIENTS = [
    'Caloric Value', 'Fat', 'Saturated Fats', 'Monounsaturated Fats', 'Polyunsaturated Fats', 
    'Carbohydrates', 'Sugars', 'Protein', 'Dietary Fiber', 'Cholesterol', 'Sodium', 'Water', 
    'Vitamin A', 'Vitamin B1', 'Vitamin B11', 'Vitamin B12', 'Vitamin B2', 'Vitamin B3', 
    'Vitamin B5', 'Vitamin B6', 'Vitamin C', 'Vitamin D', 'Vitamin E', 'Vitamin K', 'Calcium', 
    'Copper', 'Iron', 'Magnesium', 'Manganese', 'Phosphorus', 'Potassium', 'Selenium', 'Zinc', 
    'Nutrition Density'
]

HIGH_KEYWORDS = [
    "high", "rich in", "highest", "lots of", "good source", "increase",
    "more", "plenty", "boost", "contains a lot"
]

LOW_KEYWORDS = [
    "low", "low in", "reduce", "avoid", "least", "contains little",
    "lower", "decrease", "cut back"
]


def detect_nutrient_and_preference(query: str):
    q = query.lower()

    nutrient_found = None
    for nutrient in NUTRIENTS:
        # match whole words where possible
        if re.search(rf"\b{re.escape(nutrient.lower())}\b", q):
            nutrient_found = nutrient
            break

    # Detect preference (high or low)
    preference = None

    for phrase in HIGH_KEYWORDS:
        pattern = rf"\b{re.escape(phrase)}\b"
        if re.search(pattern, q):
            preference = "high"
            break

    for phrase in LOW_KEYWORDS:
        pattern = rf"\b{re.escape(phrase)}\b"
        if re.search(pattern, q):
            preference = "low"
            break

    return nutrient_found, preference


def get_high(nutrient):
    conn = sqlite3.connect('Nutrition.db')
    query = f"""
        SELECT food, "{nutrient}"
        FROM nutrition_facts
        ORDER BY "{nutrient}" DESC
        LIMIT 5;
    """
    nutrient_df = pd.read_sql_query(query, conn)
    conn.close()
    return nutrient_df

def get_low(nutrient):
    conn = sqlite3.connect('Nutrition.db')
    query = f"""
        SELECT food, "{nutrient}"
        FROM nutrition_facts
        ORDER BY "{nutrient}" ASC
        LIMIT 5;
    """
    nutrient_df = pd.read_sql_query(query, conn)
    conn.close()
    return nutrient_df

def format_hldf(nutrient_df,nutrient_col):
    context = "\n".join(
        f"- {row['food']}: {row[nutrient_col]}g {nutrient_col}"
        for _, row in nutrient_df.iterrows()
    )
    return context

def highlow_nutrients(query):
    nutrient, preference = detect_nutrient_and_preference(query)
    nutrient_df = None
    if preference == 'high':
        nutrient_df = get_high(nutrient)
    elif preference == 'low':
        nutrient_df = get_low(nutrient)
    
    

    return format_hldf(nutrient_df,nutrient)

#print(highlow_nutrients('high protein'))