{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "91d8423f-3607-42b7-8f45-4a646348ce24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.14.3-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Downloading rapidfuzz-3.14.3-cp312-cp312-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.3 MB/s  0:00:00\n",
      "Installing collected packages: rapidfuzz\n",
      "Successfully installed rapidfuzz-3.14.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471beeee-07a3-4f2e-8b46-a9456211c8ca",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b9a0546-6968-4a96-b780-e63fc7afaa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of your data:\n",
      "   Unnamed: 0.1  Unnamed: 0                              food  Caloric Value  \\\n",
      "0             0           0                      cream cheese             51   \n",
      "1             1           1                 neufchatel cheese            215   \n",
      "2             2           2  requeijao cremoso light catupiry             49   \n",
      "3             3           3                    ricotta cheese             30   \n",
      "4             4           4              cream cheese low fat             30   \n",
      "\n",
      "    Fat  Saturated Fats  Monounsaturated Fats  Polyunsaturated Fats  \\\n",
      "0   5.0             2.9                   1.3                 0.200   \n",
      "1  19.4            10.9                   4.9                 0.800   \n",
      "2   3.6             2.3                   0.9                 0.000   \n",
      "3   2.0             1.3                   0.5                 0.002   \n",
      "4   2.3             1.4                   0.6                 0.042   \n",
      "\n",
      "   Carbohydrates  Sugars  ...  Calcium  Copper   Iron  Magnesium  Manganese  \\\n",
      "0            0.8   0.500  ...    0.008  14.100  0.082      0.027      1.300   \n",
      "1            3.1   2.700  ...   99.500   0.034  0.100      8.500      0.088   \n",
      "2            0.9   3.400  ...    0.000   0.000  0.000      0.000      0.000   \n",
      "3            1.5   0.091  ...    0.097  41.200  0.097      0.096      4.000   \n",
      "4            1.2   0.900  ...   22.200   0.072  0.008      1.200      0.098   \n",
      "\n",
      "   Phosphorus  Potassium  Selenium   Zinc  Nutrition Density  \n",
      "0       0.091       15.5    19.100  0.039              7.070  \n",
      "1     117.300      129.2     0.054  0.700            130.100  \n",
      "2       0.000        0.0     0.000  0.000              5.400  \n",
      "3       0.024       30.8    43.800  0.035              5.196  \n",
      "4      22.800       37.1     0.034  0.053             27.007  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "\n",
      "Shape: 551 rows, 37 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "df = pd.read_csv('./FINAL FOOD DATASET/FOOD-DATA-GROUP1.csv')\n",
    "\n",
    "print(\"Preview of your data:\")\n",
    "print(df.head())\n",
    "print(f\"\\nShape: {df.shape[0]} rows, {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bfc3a7-2504-4dbe-992b-b4839cc3b3cf",
   "metadata": {},
   "source": [
    "## Create Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194e2668-a60e-4b69-ba1e-9cbb1fc2d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('Nutrition.db')\n",
    "df.to_sql('nutrition_facts', conn, if_exists='replace', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112df991-33fb-4fae-82a0-43a91e73e648",
   "metadata": {},
   "source": [
    "## Query DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd64713-91f5-4ea9-a311-c3ae5633feb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       food  Caloric Value  Fat  Protein  Carbohydrates\n",
      "0            shark fin soup             99  4.3      6.9            8.2\n",
      "1              swiss cheese             98  7.7      6.7            0.4\n",
      "2          limburger cheese             98  8.2      6.0            0.1\n",
      "3               tomato soup             98  0.7      2.2           22.5\n",
      "4  scrambled eggs mcdonalds             98  7.5      7.7            0.9\n",
      "5         queen crab cooked             98  1.3     20.2            0.0\n",
      "6  english muffin mcdonalds             97  2.3      5.7            2.9\n",
      "7                 crab soup             95  0.8     10.4           12.5\n",
      "8      chunky peanut butter             94  8.0      3.8            3.5\n",
      "9                    omelet             94  7.1      6.4            0.4\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('Nutrition.db')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT food, `Caloric Value`, Fat, Protein, Carbohydrates\n",
    "FROM nutrition_facts\n",
    "WHERE `Caloric Value` < 100\n",
    "ORDER BY `Caloric Value` DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(result)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "69a63212-28d8-461c-9be3-4c8b8636e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('Nutrition.db')\n",
    "\n",
    "df2 = pd.read_csv('./FINAL FOOD DATASET/FOOD-DATA-GROUP2.csv')\n",
    "df3 = pd.read_csv('./FINAL FOOD DATASET/FOOD-DATA-GROUP3.csv')\n",
    "df4 = pd.read_csv('./FINAL FOOD DATASET/FOOD-DATA-GROUP4.csv')\n",
    "df5 = pd.read_csv('./FINAL FOOD DATASET/FOOD-DATA-GROUP5.csv')\n",
    "\n",
    "df2.to_sql('nutrition_facts', conn, if_exists='append', index=False)\n",
    "df3.to_sql('nutrition_facts', conn, if_exists='append', index=False)\n",
    "df4.to_sql('nutrition_facts', conn, if_exists='append', index=False)\n",
    "df5.to_sql('nutrition_facts', conn, if_exists='append', index=False)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b0ce0e03-d2da-4efb-8c45-06f7e38a3b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [food, Caloric Value, Fat, Protein, Carbohydrates]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('Nutrition.db')\n",
    "query = \"\"\"\n",
    "SELECT food, `Caloric Value`, Fat, Protein, Carbohydrates\n",
    "FROM nutrition_facts\n",
    "WHERE food = 'groundbeef';\n",
    "\"\"\"\n",
    "\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(result)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "eefa9aed-d797-4bc6-8617-de70521d456e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   COUNT(*)\n",
      "0      2395\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('Nutrition.db')\n",
    "query = \"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM nutrition_facts;\n",
    "\"\"\"\n",
    "\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(result)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bf5c84-48a6-40cf-a08c-734c581bfc60",
   "metadata": {},
   "source": [
    "# Parse User Question for Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "12e8b450-44a0-42ef-9628-f6764c968c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "user_q = \"ground beef\"\n",
    "food_list = [\n",
    "    \"rice vinegar\",\n",
    "    \"apple cider vinegar\",\n",
    "    \"soy sauce\",\n",
    "    \"chicken breast\",\n",
    "    \"garlic\",\n",
    "    \"onion\",\n",
    "    \"olive oil\",\n",
    "    \"apple\",\n",
    "    \"cider\",\n",
    "    \"vinegar\",\n",
    "]\n",
    "food_set = set(food_list)\n",
    "food_embeddings = build_food_embeddings(food_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bcbc04-ef04-4882-a491-c874879143b2",
   "metadata": {},
   "source": [
    "## Hashset Exact Match\n",
    "Finds exact word matches between user query and database column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b5bb7642-0be0-44e6-807b-1f6dd54348b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cream cheese', 'chicken breast raw', 'mushrooms raw'], {2, 3, 5, 6, 9})"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "def preprocess(user_q):\n",
    "    user_q = user_q.lower()\n",
    "    user_q = re.sub(r\"[^a-z0-9\\s]\", \"\", user_q)\n",
    "    tokens = user_q.split()\n",
    "    return tokens\n",
    "\n",
    "def fuzzy_match_foods(token, food_set, min_score=80):\n",
    "    matches = []\n",
    "    for food in food_set:\n",
    "        score = fuzz.ratio(token, food)\n",
    "        if score >= min_score:\n",
    "            matches.append((food, score))\n",
    "    return matches\n",
    "\n",
    "def fuzzy_token_spellcheck(tokens, food_list):  \n",
    "    for i, tok in enumerate(tokens):\n",
    "        if len(tok) <= 3:\n",
    "            continue\n",
    "        matches = fuzzy_match_foods(tok, food_list)\n",
    "        if matches:\n",
    "            # Keep the best match only\n",
    "            best_food, _ = max(matches, key=lambda x: x[1])\n",
    "            tokens[i] = best_food\n",
    "    return tokens\n",
    "\n",
    "def generate_ngrams(tokens, max_n=3):\n",
    "    ngrams = []\n",
    "    n = len(tokens)\n",
    "    for size in range(max_n, 0, -1):  # start big!\n",
    "        for i in range(n - size + 1):\n",
    "            ngram = \" \".join(tokens[i:i+size])\n",
    "            ngrams.append(ngram)\n",
    "    return ngrams\n",
    "\n",
    "# This function was generated by Claude [Prompt found in Refrence 1]\n",
    "def hash_match(query, food_set, max_ngram=4):\n",
    "    tokens = preprocess(query)\n",
    "    tokens = fuzzy_token_spellcheck(tokens, food_set)\n",
    "    found = []\n",
    "    used_indices = set()  # Track which token positions have been used\n",
    "    \n",
    "    # Iterate from largest to smallest n-gram size\n",
    "    for size in range(max_ngram, 0, -1):\n",
    "        i = 0\n",
    "        while i <= len(tokens) - size:\n",
    "            # Skip if any token in this range has already been used\n",
    "            if any(idx in used_indices for idx in range(i, i + size)):\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            # Generate the n-gram\n",
    "            ngram = \" \".join(tokens[i:i+size])\n",
    "            # Check if it matches a food\n",
    "            if ngram in food_set:\n",
    "                found.append(ngram)\n",
    "                # Mark these indices as used\n",
    "                for idx in range(i, i + size):\n",
    "                    used_indices.add(idx)\n",
    "                # Move past this match\n",
    "                i += size\n",
    "            elif ngram + \" raw\" in food_set:\n",
    "                found.append(ngram + \" raw\")\n",
    "                # Mark these indices as used\n",
    "                for idx in range(i, i + size):\n",
    "                    used_indices.add(idx)\n",
    "                # Move past this match\n",
    "                i += size\n",
    "            else:\n",
    "                i += 1\n",
    "    \n",
    "    return found, used_indices\n",
    "\n",
    "hash_match(real_user_query, real_food_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa15b001-82ec-400b-b433-d73f5044d988",
   "metadata": {},
   "source": [
    "## Backup Embedding Similarity\n",
    "Catches misspelled words and other mishaps not caught by exact match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79371753-d6d7-4066-9b55-6aa64db156fc",
   "metadata": {},
   "source": [
    "### Embed Food list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "862329b0-5806-4ac8-b44f-7bc4d43dc869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# small, fast, good for semantic food names\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def build_food_embeddings(food_list):\n",
    "    food_embeddings = model.encode(food_list, convert_to_numpy=True, normalize_embeddings=True)\n",
    "    return food_embeddings\n",
    "\n",
    "food_embeddings = build_food_embeddings(food_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c1d7ed38-bfc6-4e18-a366-68b63a44fc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spelt raw', 0.3248884081840515),\n",
       " ('drum raw', 0.3018554449081421),\n",
       " ('teaseed oil', 0.2878323793411255),\n",
       " ('drum cooked', 0.2823004126548767),\n",
       " ('salsify raw', 0.28024783730506897),\n",
       " ('prunes', 0.2785925269126892),\n",
       " ('prunes stewed', 0.2721095085144043),\n",
       " ('prune juice', 0.2720765471458435),\n",
       " ('nopales raw', 0.2711069881916046),\n",
       " ('pear dried', 0.2695382535457611)]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embedding_fallback(query, food_list, food_embeddings, top_k=10, c=.0):\n",
    "    query_emb = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "    sims = np.dot(food_embeddings, query_emb)\n",
    "    \n",
    "    top_idx = np.argsort(sims)[::-1][:top_k] \n",
    "    candidates = [(food_list[i], float(sims[i])) for i in top_idx]\n",
    "    \n",
    "    filtered = [cand for cand in candidates if cand[1] >= c]\n",
    "    embedding_matches = filtered #[cand for cand in filtered if cand not in hash_matches]\n",
    "    \n",
    "    return embedding_matches\n",
    "embedding_fallback(\"unprocessed\",real_food_list, real_food_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "c6a3ebdc-5c2a-4f05-8c86-bb1f7b9de1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cream cheese',\n",
       " 'goat cheese',\n",
       " 'cheddar cheese',\n",
       " 'red wine',\n",
       " 'white wine',\n",
       " 'cooking wine',\n",
       " 'chicken sandwich',\n",
       " 'lemon chicken',\n",
       " 'meatless chicken',\n",
       " 'pork skin',\n",
       " 'pork bologna',\n",
       " 'pork loin raw',\n",
       " 'mushrooms cooked',\n",
       " 'maitake mushrooms',\n",
       " 'mushrooms raw']"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embedding_fallback_tokens(query, food_list, food_embeddings, top_k=3, c=.70):\n",
    "    tokens = preprocess(query)\n",
    "    embedding_matches = []\n",
    "    for tok in tokens:\n",
    "        tok_emb = model.encode([tok], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "        sims = np.dot(food_embeddings, tok_emb)\n",
    "    \n",
    "        top_idx = np.argsort(sims)[::-1][:top_k] \n",
    "        candidates = [(food_list[i], float(sims[i])) for i in top_idx]\n",
    "\n",
    "        filtered = [cand for cand in candidates if cand[1] >= c]   \n",
    "        filtered_strings = [item[0] for item in filtered]\n",
    "        embedding_matches = embedding_matches + filtered_strings\n",
    "\n",
    "    embedding_matches = list(dict.fromkeys(embedding_matches))\n",
    "    return embedding_matches\n",
    "\n",
    "embedding_fallback_tokens(\"I have cream cheese, wine, chicken breast, pork, and mushrooms in my fridge\",real_food_list, real_food_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "0d993e3a-ccff-4cc7-ad94-1e4aee710bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have cream cheese\n",
      "[('cream cheese', 0.8746776580810547)]\n",
      "cream cheese wine\n",
      "[('cream cheese', 0.8191268444061279)]\n",
      "chicken breast and\n",
      "[('chicken breast raw', 0.7547982931137085)]\n",
      "breast and mushrooms\n",
      "[('maitake mushrooms', 0.7185052633285522)]\n",
      "mushrooms in my\n",
      "[('mushrooms cooked', 0.7375491857528687)]\n",
      "cream cheese\n",
      "[('cream cheese', 1.0000001192092896)]\n",
      "cheese wine\n",
      "[('table wine', 0.7596521377563477)]\n",
      "wine chicken\n",
      "[('lemon chicken', 0.7232227921485901)]\n",
      "chicken breast\n",
      "[('chicken breast raw', 0.7704194784164429)]\n",
      "mushrooms in\n",
      "[('mushrooms cooked', 0.7915263175964355)]\n",
      "cream\n",
      "[('cream cheese', 0.7722978591918945)]\n",
      "cheese\n",
      "[('cream cheese', 0.822540283203125)]\n",
      "wine\n",
      "[('red wine', 0.8363298177719116)]\n",
      "chicken\n",
      "[('chicken sandwich', 0.7917603254318237)]\n",
      "mushrooms\n",
      "[('mushrooms cooked', 0.801211953163147)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cream cheese',\n",
       " 'chicken breast raw',\n",
       " 'maitake mushrooms',\n",
       " 'mushrooms cooked',\n",
       " 'table wine',\n",
       " 'lemon chicken',\n",
       " 'red wine',\n",
       " 'chicken sandwich']"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embedding_fallback_ngrams(query, food_list, food_embeddings, top_k=1, c=.70):\n",
    "    tokens = preprocess(query)\n",
    "    ngrams = generate_ngrams(tokens)\n",
    "    embedding_matches = []\n",
    "    for ngram in ngrams:\n",
    "        ngram_emb = model.encode([ngram], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "        sims = np.dot(food_embeddings, ngram_emb)\n",
    "    \n",
    "        top_idx = np.argsort(sims)[::-1][:top_k] \n",
    "        candidates = [(food_list[i], float(sims[i])) for i in top_idx]\n",
    "    \n",
    "        filtered = [cand for cand in candidates if cand[1] >= c]   \n",
    "        filtered_strings = [item[0] for item in filtered]\n",
    "        embedding_matches = embedding_matches + filtered_strings\n",
    "\n",
    "    embedding_matches = list(dict.fromkeys(embedding_matches))\n",
    "    return embedding_matches\n",
    "\n",
    "embedding_fallback_ngrams(\"I have cream cheese, wine, chicken breast, and mushrooms in my fridge\",real_food_list, real_food_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "c2f69ee0-c3e4-4eee-b658-0a407cb7f526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have cream cheese, wine, chicken breast, pork, and mushrooms in my fridge\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cream cheese', 0.5539529919624329),\n",
       " ('mushrooms raw', 0.5100688934326172),\n",
       " ('cottage cheese creamed', 0.5043703317642212),\n",
       " ('cream of mushroom soup', 0.5021468997001648),\n",
       " ('mushrooms cooked', 0.5009106993675232),\n",
       " ('monterey cheese', 0.4958856701850891),\n",
       " ('cream cheese fat free', 0.4870794117450714),\n",
       " ('portabella mushrooms raw', 0.4865381419658661),\n",
       " ('frijoles with cheese', 0.4795270562171936),\n",
       " ('nachos with cheese', 0.47944411635398865)]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embedding_sim_test(query, food_list, food_embeddings, top_k=10):\n",
    "    print(query)\n",
    "    query_emb = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "    sims = np.dot(food_embeddings, query_emb)\n",
    "    \n",
    "    top_idx = np.argsort(sims)[::-1][:top_k] \n",
    "    candidates = [(food_list[i], float(sims[i])) for i in top_idx]\n",
    "    return candidates\n",
    "\n",
    "embedding_sim_test(\"I have cream cheese, wine, chicken breast, pork, and mushrooms in my fridge\",real_food_list, real_food_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f4958-34a5-4638-b83a-eeeddfb14da7",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f8ccf66a-4c55-4154-8653-c7896c097d61",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[262], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m     embedding_matches \u001b[38;5;241m=\u001b[39m embedding_fallback_tokens(query, food_list, food_embeddings, hash_matches, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhashset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m\"\u001b[39m: hash_matches}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m\"\u001b[39m: embedding_matches}\n\u001b[1;32m----> 8\u001b[0m match_food(user_q, food_list, food_set, food_embeddings)\n",
      "Cell \u001b[1;32mIn[262], line 4\u001b[0m, in \u001b[0;36mmatch_food\u001b[1;34m(query, food_list, food_set, food_embeddings, max_ngram)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatch_food\u001b[39m(query, food_list, food_set, food_embeddings, max_ngram\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m      2\u001b[0m     hash_matches \u001b[38;5;241m=\u001b[39m hash_match(query, food_set, max_ngram\u001b[38;5;241m=\u001b[39mmax_ngram)\n\u001b[1;32m----> 4\u001b[0m     embedding_matches \u001b[38;5;241m=\u001b[39m embedding_fallback_tokens(query, food_list, food_embeddings, hash_matches, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhashset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m\"\u001b[39m: hash_matches}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m\"\u001b[39m: embedding_matches}\n",
      "Cell \u001b[1;32mIn[261], line 12\u001b[0m, in \u001b[0;36membedding_fallback_tokens\u001b[1;34m(query, food_list, food_embeddings, hash_matches, top_k, c)\u001b[0m\n\u001b[0;32m      9\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m [(food_list[i], \u001b[38;5;28mfloat\u001b[39m(sims[i])) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m top_idx]\n\u001b[0;32m     11\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m [cand[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m cand \u001b[38;5;129;01min\u001b[39;00m candidates \u001b[38;5;28;01mif\u001b[39;00m cand[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m c]\n\u001b[1;32m---> 12\u001b[0m     embedding_matches \u001b[38;5;241m=\u001b[39m embedding_matches\u001b[38;5;241m.\u001b[39mappend(filtered)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embedding_matches\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "def match_food(query, food_list, food_set, food_embeddings, max_ngram=4):\n",
    "    hash_matches = hash_match(query, food_set, max_ngram=max_ngram)\n",
    "    \n",
    "    embedding_matches = embedding_fallback_tokens(query, food_list, food_embeddings, hash_matches, top_k=10)\n",
    "    \n",
    "    return {\"method\": \"hashset\", \"matches\": hash_matches}, {\"method\": \"embedding\", \"matches\": embedding_matches}\n",
    "\n",
    "match_food(user_q, food_list, food_set, food_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e417cd17-7572-4d20-bb1f-980c936e0005",
   "metadata": {},
   "source": [
    "# Querying DB with retrieved food names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e3e1e037-3ed8-438d-99cc-8e2895b2a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('Nutrition.db')\n",
    "query = \"\"\"\n",
    "SELECT food\n",
    "FROM nutrition_facts;\n",
    "\"\"\"\n",
    "real_food_df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "real_food_list = real_food_df['food'].tolist()\n",
    "\n",
    "real_food_set = set(real_food_list)\n",
    "real_food_embeddings = build_food_embeddings(real_food_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "808093e4-225a-4a87-93ef-043244054ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'chicken breast' in real_food_set:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2b25fefd-3cf8-4a5c-8308-648fbc07f281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cream cheese', 'chicken breast raw', 'mushrooms raw']\n"
     ]
    }
   ],
   "source": [
    "real_user_query = \"I have cream cheese, wine, chicken breast, pork, and mushrooms in my fridge\"\n",
    "hashset_dict, embedding_dict = match_food(real_user_query, real_food_list, real_food_set, real_food_embeddings)\n",
    "match_list = hashset_dict['matches'] # + embedding_dict['matches']\n",
    "print(match_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2f28f2bf-8b53-410b-9dbe-b871d9c3ca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0           food  Caloric Value  Fat  \\\n",
      "0             0           0   cream cheese             51  5.0   \n",
      "1           708         708  mushrooms raw             15  0.2   \n",
      "\n",
      "   Saturated Fats  Monounsaturated Fats  Polyunsaturated Fats  Carbohydrates  \\\n",
      "0           2.900                   1.3                   0.2            0.8   \n",
      "1           0.052                   0.0                   0.1            2.3   \n",
      "\n",
      "   Sugars  ...  Calcium  Copper   Iron  Magnesium  Manganese  Phosphorus  \\\n",
      "0     0.5  ...    0.008    14.1  0.082      0.027      1.300       0.091   \n",
      "1     1.4  ...    2.100     0.2  0.400      6.300      0.042      60.200   \n",
      "\n",
      "   Potassium  Selenium   Zinc  Nutrition Density  \n",
      "0       15.5    19.100  0.039               7.07  \n",
      "1      222.6     0.061  0.400               9.40  \n",
      "\n",
      "[2 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('Nutrition.db')\n",
    "placeholders = ','.join('?' * len(match_list))\n",
    "query = f\"\"\"\n",
    "SELECT *\n",
    "FROM nutrition_facts\n",
    "WHERE food IN ({placeholders});\n",
    "\"\"\"\n",
    "\n",
    "result = pd.read_sql_query(query, conn, params=match_list)\n",
    "print(result)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6498466b-b638-4f01-9ea9-a9241890037e",
   "metadata": {},
   "source": [
    "# Reference and AI Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558f739-9a3b-41ac-a629-e13a0c3b769d",
   "metadata": {},
   "source": [
    "[1]\n",
    "Claude prompt:\n",
    "```import re\n",
    "def preprocess(user_q):\n",
    "    user_q = user_q.lower()\n",
    "    user_q = re.sub(r\"[^a-z0-9\\s]\", \"\", user_q)\n",
    "    tokens = user_q.split()\n",
    "    return tokens\n",
    "def generate_ngrams(tokens, max_n=4):\n",
    "    ngrams = []\n",
    "    n = len(tokens)\n",
    "    for size in range(max_n, 0, -1):  # start big!\n",
    "        for i in range(n - size + 1):\n",
    "            ngram = \" \".join(tokens[i:i+size])\n",
    "            ngrams.append(ngram)\n",
    "    return ngrams\n",
    "def match_foods_hashset(query, food_set, max_ngram=4):\n",
    "    tokens = preprocess(query)\n",
    "    ngrams = generate_ngrams(tokens, max_n=max_ngram)\n",
    "    found = []\n",
    "    for ng in reversed(ngrams):\n",
    "        if ng in food_set:\n",
    "            found.append(ng)\n",
    "    return found\n",
    "\n",
    "user_q= \"I have apple cider vinegar and onion in my fridge\"\n",
    "food_list = [\n",
    "    \"rice vinegar\",\n",
    "    \"apple cider vinegar\",\n",
    "    \"soy sauce\",\n",
    "    \"chicken breast\",\n",
    "    \"garlic\",\n",
    "    \"onion\",\n",
    "    \"olive oil\",\n",
    "    \"apple\",\n",
    "    \"cider\",\n",
    "    \"vinegar\",\n",
    "]\n",
    "```\n",
    "\"I've got this code to find matches in food lists, I put an example of a user query and food list above. The problem right now is the code will return vinegar, cider, apple and apple cider vinegar. I could have it only return the largest ngram, but that will cut out onion. So what I want to do I check for ngram matches between each iteration of ngram generation then if there is a match remove the words. \n",
    "\n",
    "Of course we will start with larger n-gram. for example we will generate 4-grams for the user query and find not match, then we will generate 3-grams and find 'apple cider vinegar', we save it and remove 'apple', 'cider', and 'vinegar' from the token list. then we find nothing in 2 ngram and in 1-gram we find only onion since the other words have been removed.\n",
    "\n",
    "can you write up a script for that?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e42a8-e0e5-4b43-a75f-0ddbc85ef1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
